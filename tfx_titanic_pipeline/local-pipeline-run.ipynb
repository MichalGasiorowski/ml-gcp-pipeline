{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous training with TFX and Google Cloud AI Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "1.  Use the TFX CLI to build a TFX pipeline.\n",
    "2.  Deploy a TFX pipeline version without tuning to a hosted AI Platform Pipelines instance.\n",
    "3.  Create and monitor a TFX pipeline run using the TFX CLI.\n",
    "4.  Deploy a new TFX pipeline version with tuning enabled to a hosted AI Platform Pipelines instance.\n",
    "5.  Create and monitor another TFX pipeline run directly in the KFP UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you use utilize the following tools and services to deploy and run a TFX pipeline on Google Cloud that automates the development and deployment of a TensorFlow 2.3 WideDeep Classifer to predict forest cover from cartographic data:\n",
    "\n",
    "* The [**TFX CLI**](https://www.tensorflow.org/tfx/guide/cli) utility to build and deploy a TFX pipeline.\n",
    "* A hosted [**AI Platform Pipeline instance (Kubeflow Pipelines)**](https://www.tensorflow.org/tfx/guide/kubeflow) for TFX pipeline orchestration.\n",
    "* [**Dataflow**](https://cloud.google.com/dataflow) jobs for scalable, distributed data processing for TFX components.\n",
    "* A [**AI Platform Training**](https://cloud.google.com/ai-platform/) job for model training and flock management for parallel tuning trials. \n",
    "* [**AI Platform Prediction**](https://cloud.google.com/ai-platform/) as a model server destination for blessed pipeline model versions.\n",
    "* [**CloudTuner**](https://www.tensorflow.org/tfx/guide/tuner#tuning_on_google_cloud_platform_gcp) and [**AI Platform Vizier**](https://cloud.google.com/ai-platform/optimizer/docs/overview) for advanced model hyperparameter tuning using the Vizier algorithm.\n",
    "\n",
    "You will then create and monitor pipeline runs using the TFX CLI as well as the KFP UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update lab environment PATH to include TFX CLI and skaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/michal/.local/bin:/home/michal/venv/ML-3.8/bin:/home/michal/google-cloud-sdk/bin:/home/michal/anaconda3/bin:/home/michal/anaconda3/condabin:/home/michal/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Set `PATH` to include the directory containing TFX CLI and skaffold.\n",
    "PATH=%env PATH\n",
    "HOME=%env HOME\n",
    "\n",
    "%env PATH={HOME}/.local/bin:{PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate lab package version installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFX version: 0.25.0\n",
      "KFP version: 1.0.4\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import tfx; print('TFX version: {}'.format(tfx.__version__))\"\n",
    "!python -c \"import kfp; print('KFP version: {}'.format(kfp.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: this lab was built and tested with the following package versions:\n",
    "\n",
    "`TFX version: 0.25.0`  \n",
    "`KFP version: 1.0.4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup local path to data, train, test folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_path=os.getcwd()\n",
    "local_data_dirpath = os.path.join(notebook_path, 'data')\n",
    "\n",
    "local_train_dirpath = os.path.join(local_data_dirpath, \"train\")\n",
    "local_train_filepath = os.path.join(local_train_dirpath, \"train.csv\")\n",
    "local_test_dirpath = os.path.join(local_data_dirpath, \"test\")\n",
    "local_test_filepath = os.path.join(local_test_dirpath, \"test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat 'kaggle.json': No such file or directory\n",
      "rm: cannot remove 'kaggle.json': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!pip install -q kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!rm kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data from kaggle, unzip it and copy it to data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading titanic.zip to /home/michal/PycharmProjects/ml-gcp-pipeline/tfx_titanic_pipeline/data\n",
      "  0%|                                               | 0.00/34.1k [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 34.1k/34.1k [00:00<00:00, 2.28MB/s]\n",
      "Archive:  /home/michal/PycharmProjects/ml-gcp-pipeline/tfx_titanic_pipeline/data/titanic.zip\n",
      "  inflating: /home/michal/PycharmProjects/ml-gcp-pipeline/tfx_titanic_pipeline/data/gender_submission.csv  \n",
      "  inflating: /home/michal/PycharmProjects/ml-gcp-pipeline/tfx_titanic_pipeline/data/test.csv  \n",
      "  inflating: /home/michal/PycharmProjects/ml-gcp-pipeline/tfx_titanic_pipeline/data/train.csv  \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c titanic -p {local_data_dirpath} --force\n",
    "!unzip -o {local_data_dirpath}/\"titanic.zip\" -d {local_data_dirpath}\n",
    "!cp {local_data_dirpath}/\"train.csv\" {local_train_filepath}\n",
    "!cp {local_data_dirpath}/\"test.csv\" {local_test_filepath}\n",
    "\n",
    "# clean up\n",
    "!rm  {local_data_dirpath}/*.csv  {local_data_dirpath}/*.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://data/train/train.csv [Content-Type=text/csv]...\n",
      "- [1 files][ 59.8 KiB/ 59.8 KiB]                                                \n",
      "Operation completed over 1 objects/59.8 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp data/train/train.csv gs://cloud-training-281409-kubeflowpipelines-default/tfx-template/data/titanic/data.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `config.py` module configures the default values for the environment specific settings and the default values for the pipeline runtime parameters. \n",
    "The default values can be overwritten at compile time by providing the updated values in a set of environment variables. You will set custom environment variables later on this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pipeline.py` module contains the TFX DSL defining the workflow implemented by the pipeline.\n",
    "\n",
    "The `preprocessing.py` module implements the data preprocessing logic  the `Transform` component.\n",
    "\n",
    "The `model.py` module implements the training, tuning, and model building logic for the `Trainer` and `Tuner` components.\n",
    "\n",
    "The `runner.py` module configures and executes `LocalDagRunner`. At compile time, the `LocalDagRunner.run()` method converts the TFX DSL into the pipeline package in the [argo](https://argoproj.github.io/argo/) format for execution on your hosted AI Platform Pipelines instance.\n",
    "\n",
    "The `features.py` module contains feature definitions common across `preprocessing.py` and `model.py`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure your environment resource settings\n",
    "\n",
    "Update  the below constants  with the settings reflecting your lab environment. \n",
    "\n",
    "- `GCP_REGION` - the compute region for AI Platform Training, Vizier, and Prediction.\n",
    "- `ARTIFACT_STORE` - An existing GCS bucket. You can use any bucket or use the GCS bucket created during installation of AI Platform Pipelines. The default bucket name will contain the `kubeflowpipelines-` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://artifacts.cloud-training-281409.appspot.com/\r\n",
      "gs://cloud-training-281409/\r\n",
      "gs://cloud-training-281409-kubeflowpipelines-default/\r\n",
      "gs://kubeflow-storage-goose/\r\n"
     ]
    }
   ],
   "source": [
    "# Use the following command to identify the GCS bucket for metadata and pipeline storage.\n",
    "!gsutil ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `CUSTOM_SERVICE_ACCOUNT` - In the gcp console Click on the Navigation Menu. Navigate to `IAM & Admin`, then to `Service Accounts` and use the service account starting with prefix - `'tfx-tuner-caip-service-account'`. This enables CloudTuner and the Google Cloud AI Platform extensions Tuner component to work together and allows for distributed and parallel tuning backed by AI Platform Vizier's hyperparameter search algorithm. Please see the lab setup `README` for setup instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ENDPOINT` - set the `ENDPOINT` constant to the endpoint to your AI Platform Pipelines instance. The endpoint to the AI Platform Pipelines instance can be found on the [AI Platform Pipelines](https://console.cloud.google.com/ai-platform/pipelines/clusters) page in the Google Cloud Console. Open the *SETTINGS* for your instance and use the value of the `host` variable in the *Connect to this Kubeflow Pipelines instance from a Python client via Kubeflow Pipelines SKD* section of the *SETTINGS* window. The format is `'...pipelines.googleusercontent.com'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Set your environment resource settings here for GCP_REGION, ARTIFACT_STORE_URI, ENDPOINT, and CUSTOM_SERVICE_ACCOUNT.\n",
    "GCP_REGION = 'us-central1'\n",
    "ARTIFACT_STORE_URI = os.path.join(os.sep, HOME, 'artifact-store')\n",
    "ENDPOINT = 'https://2d1c9ffe87c3f159-dot-us-central1.pipelines.googleusercontent.com'\n",
    "CUSTOM_SERVICE_ACCOUNT = 'tfx-tuner-service-account@cloud-training-281409.iam.gserviceaccount.com'\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GCP_REGION=us-central1\n",
      "env: ARTIFACT_STORE_URI=/home/michal/artifact-store\n",
      "env: CUSTOM_SERVICE_ACCOUNT=tfx-tuner-service-account@cloud-training-281409.iam.gserviceaccount.com\n",
      "env: PROJECT_ID=cloud-training-281409\n"
     ]
    }
   ],
   "source": [
    "# Set your resource settings as environment variables. These override the default values in pipeline/config.py.\n",
    "%env GCP_REGION={GCP_REGION}\n",
    "%env ARTIFACT_STORE_URI={ARTIFACT_STORE_URI}\n",
    "%env CUSTOM_SERVICE_ACCOUNT={CUSTOM_SERVICE_ACCOUNT}\n",
    "%env PROJECT_ID={PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the compile time settings to first create a pipeline version without hyperparameter tuning\n",
    "\n",
    "Default pipeline runtime environment values are configured in the pipeline folder `config.py`. You will set their values directly below:\n",
    "\n",
    "* `PIPELINE_NAME` - the pipeline's globally unique name. For each pipeline update, each pipeline version uploaded to KFP will be reflected on the `Pipelines` tab in the `Pipeline name > Version name` dropdown in the format `PIPELINE_NAME_datetime.now()`.\n",
    "\n",
    "* `MODEL_NAME` - the pipeline's unique model output name for AI Platform Prediction. For multiple pipeline runs, each pushed blessed model will create a new version with the format `'v{}'.format(int(time.time()))`.\n",
    "\n",
    "* `DATA_ROOT_URI` - the URI for the raw lab dataset `gs://workshop-datasets/covertype/small`.\n",
    "\n",
    "* `CUSTOM_TFX_IMAGE` - the image name of your pipeline container build by skaffold and published by `Cloud Build` to `Cloud Container Registry` in the format `'gcr.io/{}/{}'.format(PROJECT_ID, PIPELINE_NAME)`.\n",
    "\n",
    "* `RUNTIME_VERSION` - the TensorFlow runtime version. This lab was built and tested using TensorFlow `2.3`.\n",
    "\n",
    "* `PYTHON_VERSION` - the Python runtime version. This lab was built and tested using Python `3.7`.\n",
    "\n",
    "* `USE_KFP_SA` - The pipeline can run using a security context of the GKE default node pool's service account or the service account defined in the `user-gcp-sa` secret of the Kubernetes namespace hosting Kubeflow Pipelines. If you want to use the `user-gcp-sa` service account you change the value of `USE_KFP_SA` to `True`. Note that the default AI Platform Pipelines configuration does not define the `user-gcp-sa` secret.\n",
    "\n",
    "* `ENABLE_TUNING` - boolean value indicating whether to add the `Tuner` component to the pipeline or use hyperparameter defaults. See the `model.py` and `pipeline.py` files for details on how this changes the pipeline topology across pipeline versions. You will create pipeline versions without and with tuning enabled in the subsequent lab exercises for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'tfx-titanic-training'\n",
    "MODEL_NAME = 'tfx_titanic_classifier'\n",
    "DATA_ROOT_URI = local_train_dirpath\n",
    "CUSTOM_TFX_IMAGE = 'gcr.io/{}/{}'.format(PROJECT_ID, PIPELINE_NAME)\n",
    "RUNTIME_VERSION = '2.3'\n",
    "PYTHON_VERSION = '3.7'\n",
    "USE_KFP_SA=False\n",
    "ENABLE_TUNING=False\n",
    "ENABLE_CACHE=True\n",
    "#ENABLE_TUNING=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PIPELINE_NAME=tfx-titanic-training\n",
      "env: MODEL_NAME=tfx_titanic_classifier\n",
      "env: DATA_ROOT_URI=/home/michal/PycharmProjects/ml-gcp-pipeline/tfx_titanic_pipeline/data/train\n",
      "env: KUBEFLOW_TFX_IMAGE=gcr.io/cloud-training-281409/tfx-titanic-training\n",
      "env: RUNTIME_VERSION=2.3\n",
      "env: PYTHON_VERIONS=3.7\n",
      "env: USE_KFP_SA=False\n",
      "env: ENABLE_TUNING=False\n",
      "env: ENABLE_CACHE=True\n"
     ]
    }
   ],
   "source": [
    "%env PIPELINE_NAME={PIPELINE_NAME}\n",
    "%env MODEL_NAME={MODEL_NAME}\n",
    "%env DATA_ROOT_URI={DATA_ROOT_URI}\n",
    "%env KUBEFLOW_TFX_IMAGE={CUSTOM_TFX_IMAGE}\n",
    "%env RUNTIME_VERSION={RUNTIME_VERSION}\n",
    "%env PYTHON_VERIONS={PYTHON_VERSION}\n",
    "%env USE_KFP_SA={USE_KFP_SA}\n",
    "%env ENABLE_TUNING={ENABLE_TUNING}\n",
    "%env ENABLE_CACHE={ENABLE_CACHE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's upload our sample data to GCS bucket so that we can use it in our pipeline later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/michal/PycharmProjects/ml-gcp-pipeline/tfx_titanic_pipeline/pipeline\n"
     ]
    }
   ],
   "source": [
    "%cd {notebook_path}/pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-29 23:19:40.761789: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n",
      "INFO:absl:Cleaning local log folder : /tmp/logs\n",
      "INFO:absl:train_steps for training: 30000\n",
      "INFO:absl:tuner_steps for tuning: 2000\n",
      "INFO:absl:data_root_uri for training: gs://cloud-training-281409-kubeflowpipelines-default/tfx-template/data/titanic\n",
      "INFO:absl:eval_steps for evaluating: 1000\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
      "INFO:absl:Component CsvExampleGen is running.\n",
      "INFO:absl:Running driver for CsvExampleGen\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:select span and version = (0, None)\n",
      "INFO:absl:latest span and version = (0, None)\n",
      "INFO:absl:Running executor for CsvExampleGen\n",
      "INFO:absl:Generating examples.\n",
      "INFO:absl:Processing input csv data gs://cloud-training-281409-kubeflowpipelines-default/tfx-template/data/titanic/* to TFExample.\n",
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "INFO:absl:Examples generated.\n",
      "INFO:absl:Running publisher for CsvExampleGen\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component CsvExampleGen is finished.\n",
      "INFO:absl:Component ImporterNode.import_user_schema is running.\n",
      "INFO:absl:Running driver for ImporterNode.import_user_schema\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Processing source uri: schema, properties: {}, custom_properties: {}\n",
      "2021-03-29 23:19:54.507996: W ml_metadata/metadata_store/rdbms_metadata_access_object.cc:588] No property is defined for the Type\n",
      "INFO:absl:Running executor for ImporterNode.import_user_schema\n",
      "INFO:absl:Running publisher for ImporterNode.import_user_schema\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component ImporterNode.import_user_schema is finished.\n",
      "INFO:absl:Component ResolverNode.latest_blessed_model_resolver is running.\n",
      "INFO:absl:Running driver for ResolverNode.latest_blessed_model_resolver\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running publisher for ResolverNode.latest_blessed_model_resolver\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component ResolverNode.latest_blessed_model_resolver is finished.\n",
      "INFO:absl:Component StatisticsGen is running.\n",
      "INFO:absl:Running driver for StatisticsGen\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for StatisticsGen\n",
      "INFO:absl:Generating statistics for split train.\n",
      "INFO:absl:Statistics for split train written to /home/michal/artifact-store/tfx-titanic-training/20210329_231949/StatisticsGen/statistics/4/train.\n",
      "INFO:absl:Generating statistics for split eval.\n",
      "INFO:absl:Statistics for split eval written to /home/michal/artifact-store/tfx-titanic-training/20210329_231949/StatisticsGen/statistics/4/eval.\n",
      "2021-03-29 23:19:55.601827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-03-29 23:19:55.727170: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-03-29 23:19:55.727227: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (michal-ubuntu20-vm): /proc/driver/nvidia/version does not exist\n",
      "2021-03-29 23:19:55.727495: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-29 23:19:55.744312: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 4008000000 Hz\n",
      "2021-03-29 23:19:55.744615: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x81799d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-29 23:19:55.744648: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "INFO:absl:Running publisher for StatisticsGen\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component StatisticsGen is finished.\n",
      "INFO:absl:Component Transform is running.\n",
      "INFO:absl:Running driver for Transform\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "2021-03-29 23:19:56.807489: W ml_metadata/metadata_store/rdbms_metadata_access_object.cc:588] No property is defined for the Type\n",
      "2021-03-29 23:19:56.810575: W ml_metadata/metadata_store/rdbms_metadata_access_object.cc:588] No property is defined for the Type\n",
      "INFO:absl:Running executor for Transform\n",
      "INFO:absl:Analyze the 'train' split and transform all splits when splits_config is not set.\n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tfx/components/transform/executor.py:528: Schema (from tensorflow_transform.tf_metadata.dataset_schema) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Schema is a deprecated, use schema_utils.schema_from_feature_spec to create a `Schema`\n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tfx/components/transform/executor.py:528: Schema (from tensorflow_transform.tf_metadata.dataset_schema) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Schema is a deprecated, use schema_utils.schema_from_feature_spec to create a `Schema`\n",
      "INFO:absl:Feature Embarked has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Ticket has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Sex has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Name has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cabin has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Age has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Fare has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Parch has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature PassengerId has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Pclass has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature SibSp has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Survived has no shape. Setting to VarLenSparseTensor.\n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tensorflow_transform/tf_utils.py:250: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tensorflow_transform/tf_utils.py:250: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "INFO:absl:Feature Embarked has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Ticket has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Sex has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Name has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cabin has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Age has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Fare has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Parch has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature PassengerId has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Pclass has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature SibSp has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Survived has no shape. Setting to VarLenSparseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Feature Embarked has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Ticket has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Sex has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Name has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cabin has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Age has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Fare has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Parch has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature PassengerId has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Pclass has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature SibSp has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Survived has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Embarked has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Ticket has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Sex has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Name has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cabin has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Age has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Fare has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Parch has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature PassengerId has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Pclass has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature SibSp has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Survived has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Embarked has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Ticket has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Sex has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Name has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cabin has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Age has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Fare has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Parch has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature PassengerId has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Pclass has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature SibSp has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Survived has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Embarked has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Ticket has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Sex has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Name has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cabin has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Age has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Fare has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Parch has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature PassengerId has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Pclass has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature SibSp has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Survived has no shape. Setting to VarLenSparseTensor.\n",
      "WARNING:tensorflow:TFT beam APIs accept both the TFXIO format and the instance dict format now. There is no need to set use_tfxio any more and it will be removed soon.\n",
      "WARNING:tensorflow:TFT beam APIs accept both the TFXIO format and the instance dict format now. There is no need to set use_tfxio any more and it will be removed soon.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType]] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType]] instead.\n",
      "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:200: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:200: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "INFO:absl:Feature Embarked has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Ticket has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Sex has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Name has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cabin has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Age has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Fare has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Parch has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature PassengerId has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Pclass has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature SibSp has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Survived has no shape. Setting to VarLenSparseTensor.\n",
      "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
      "INFO:absl:Feature Embarked has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Ticket has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Sex has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Name has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cabin has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Age has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Fare has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Parch has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature PassengerId has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Pclass has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature SibSp has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Survived has no shape. Setting to VarLenSparseTensor.\n",
      "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_7:0\\022/vocab_compute_and_apply_vocabulary_2_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_7:0\\022/vocab_compute_and_apply_vocabulary_2_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_7:0\\022/vocab_compute_and_apply_vocabulary_2_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_7:0\\022/vocab_compute_and_apply_vocabulary_2_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_7:0\\022/vocab_compute_and_apply_vocabulary_2_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_7:0\\022/vocab_compute_and_apply_vocabulary_2_vocabulary\"\n",
      "\n",
      "INFO:absl:Running publisher for Transform\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Transform is finished.\n",
      "INFO:absl:Component ExampleValidator is running.\n",
      "INFO:absl:Running driver for ExampleValidator\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for ExampleValidator\n",
      "INFO:absl:Validating schema against the computed statistics for split train.\n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tensorflow_data_validation/utils/stats_util.py:247: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tensorflow_data_validation/utils/stats_util.py:247: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:absl:Validation complete for split train. Anomalies written to /home/michal/artifact-store/tfx-titanic-training/20210329_231949/ExampleValidator/anomalies/6/train.\n",
      "INFO:absl:Validating schema against the computed statistics for split eval.\n",
      "INFO:absl:Validation complete for split eval. Anomalies written to /home/michal/artifact-store/tfx-titanic-training/20210329_231949/ExampleValidator/anomalies/6/eval.\n",
      "INFO:absl:Running publisher for ExampleValidator\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component ExampleValidator is finished.\n",
      "INFO:absl:Component SchemaGen is running.\n",
      "INFO:absl:Running driver for SchemaGen\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for SchemaGen\n",
      "INFO:absl:Processing schema from statistics for split train.\n",
      "INFO:absl:Processing schema from statistics for split eval.\n",
      "INFO:absl:Schema written to /home/michal/artifact-store/tfx-titanic-training/20210329_231949/SchemaGen/schema/7/schema.pbtxt.\n",
      "INFO:absl:Running publisher for SchemaGen\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component SchemaGen is finished.\n",
      "INFO:absl:Component Trainer is running.\n",
      "INFO:absl:Running driver for Trainer\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "2021-03-29 23:20:03.639915: W ml_metadata/metadata_store/rdbms_metadata_access_object.cc:588] No property is defined for the Type\n",
      "2021-03-29 23:20:03.643418: W ml_metadata/metadata_store/rdbms_metadata_access_object.cc:588] No property is defined for the Type\n",
      "INFO:absl:Running executor for Trainer\n",
      "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
      "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "INFO:absl:Training model.\n",
      "INFO:absl:Feature Age_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature Embarked_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature Fare_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature Parch_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature Pclass_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature Sex_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature SibSp_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature Survived_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature Age_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature Embarked_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature Fare_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature Parch_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature Pclass_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature Sex_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature SibSp_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:Feature Survived_xf has a shape . Setting to DenseTensor.\n",
      "INFO:absl:HyperParameters for training: {'space': [{'class_name': 'Float', 'config': {'name': 'learning_rate', 'default': 0.0009167702421017742, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}}, {'class_name': 'Int', 'config': {'name': 'n_layers', 'default': 2, 'conditions': [], 'min_value': 1, 'max_value': 2, 'step': 1, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'n_units_1', 'default': 72, 'conditions': [{'class_name': 'Parent', 'config': {'name': 'n_layers', 'values': [1]}}], 'min_value': 8, 'max_value': 128, 'step': 8, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'n_units_1', 'default': 128, 'conditions': [{'class_name': 'Parent', 'config': {'name': 'n_layers', 'values': [2]}}], 'min_value': 8, 'max_value': 128, 'step': 8, 'sampling': None}}, {'class_name': 'Int', 'config': {'name': 'n_units_2', 'default': 80, 'conditions': [{'class_name': 'Parent', 'config': {'name': 'n_layers', 'values': [2]}}], 'min_value': 8, 'max_value': 128, 'step': 8, 'sampling': None}}], 'values': {'learning_rate': 0.0009167702421017742, 'n_layers': 2, 'n_units_1': 128, 'n_units_2': 80}}\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Model: \"functional_1\"\n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "INFO:absl:==================================================================================================\n",
      "INFO:absl:Age_xf (InputLayer)             [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Embarked_xf (InputLayer)        [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Fare_xf (InputLayer)            [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Parch_xf (InputLayer)           [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Pclass_xf (InputLayer)          [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Sex_xf (InputLayer)             [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:SibSp_xf (InputLayer)           [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_features (DenseFeatures)  (None, 2)            0           Age_xf[0][0]                     \n",
      "INFO:absl:                                                                 Embarked_xf[0][0]                \n",
      "INFO:absl:                                                                 Fare_xf[0][0]                    \n",
      "INFO:absl:                                                                 Parch_xf[0][0]                   \n",
      "INFO:absl:                                                                 Pclass_xf[0][0]                  \n",
      "INFO:absl:                                                                 Sex_xf[0][0]                     \n",
      "INFO:absl:                                                                 SibSp_xf[0][0]                   \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense (Dense)                   (None, 128)          384         dense_features[0][0]             \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_1 (Dense)                 (None, 80)           10320       dense[0][0]                      \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_features_1 (DenseFeatures (None, 3050)         0           Age_xf[0][0]                     \n",
      "INFO:absl:                                                                 Embarked_xf[0][0]                \n",
      "INFO:absl:                                                                 Fare_xf[0][0]                    \n",
      "INFO:absl:                                                                 Parch_xf[0][0]                   \n",
      "INFO:absl:                                                                 Pclass_xf[0][0]                  \n",
      "INFO:absl:                                                                 Sex_xf[0][0]                     \n",
      "INFO:absl:                                                                 SibSp_xf[0][0]                   \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:concatenate (Concatenate)       (None, 3130)         0           dense_1[0][0]                    \n",
      "INFO:absl:                                                                 dense_features_1[0][0]           \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_2 (Dense)                 (None, 1)            3131        concatenate[0][0]                \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:tf_op_layer_Squeeze (TensorFlow [(None,)]            0           dense_2[0][0]                    \n",
      "INFO:absl:==================================================================================================\n",
      "INFO:absl:Total params: 13,835\n",
      "INFO:absl:Trainable params: 13,835\n",
      "INFO:absl:Non-trainable params: 0\n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "2021-03-29 23:20:04.218191: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "Epoch 1/20\n",
      "2021-03-29 23:20:06.979769: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "2021-03-29 23:20:07.034968: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/logs/train/plugins/profile/2021_03_29_23_20_07\n",
      "2021-03-29 23:20:07.037332: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to /tmp/logs/train/plugins/profile/2021_03_29_23_20_07/michal-ubuntu20-vm.trace.json.gz\n",
      "2021-03-29 23:20:07.054665: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: /tmp/logs/train/plugins/profile/2021_03_29_23_20_07\n",
      "2021-03-29 23:20:07.054786: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to /tmp/logs/train/plugins/profile/2021_03_29_23_20_07/michal-ubuntu20-vm.memory_profile.json.gz\n",
      "2021-03-29 23:20:07.058056: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: /tmp/logs/train/plugins/profile/2021_03_29_23_20_07Dumped tool data for xplane.pb to /tmp/logs/train/plugins/profile/2021_03_29_23_20_07/michal-ubuntu20-vm.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /tmp/logs/train/plugins/profile/2021_03_29_23_20_07/michal-ubuntu20-vm.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /tmp/logs/train/plugins/profile/2021_03_29_23_20_07/michal-ubuntu20-vm.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /tmp/logs/train/plugins/profile/2021_03_29_23_20_07/michal-ubuntu20-vm.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /tmp/logs/train/plugins/profile/2021_03_29_23_20_07/michal-ubuntu20-vm.kernel_stats.pb\n",
      "\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0276s vs `on_train_batch_end` time: 0.0513s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0276s vs `on_train_batch_end` time: 0.0513s). Check your callbacks.\n",
      "1500/1500 - 11s - loss: 0.5197 - tp: 17237.0000 - fp: 3875.0000 - tn: 56700.0000 - fn: 18188.0000 - binary_accuracy: 0.7702 - precision: 0.8165 - recall: 0.4866 - auc: 0.8124 - val_loss: 0.4426 - val_tp: 20333.0000 - val_fp: 5269.0000 - val_tn: 30118.0000 - val_fn: 8280.0000 - val_binary_accuracy: 0.7883 - val_precision: 0.7942 - val_recall: 0.7106 - val_auc: 0.8898\n",
      "Epoch 2/20\n",
      "1500/1500 - 11s - loss: 0.4617 - tp: 23570.0000 - fp: 7485.0000 - tn: 53108.0000 - fn: 11837.0000 - binary_accuracy: 0.7987 - precision: 0.7590 - recall: 0.6657 - auc: 0.8358 - val_loss: 0.4264 - val_tp: 21838.0000 - val_fp: 5646.0000 - val_tn: 29741.0000 - val_fn: 6775.0000 - val_binary_accuracy: 0.8059 - val_precision: 0.7946 - val_recall: 0.7632 - val_auc: 0.8890\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 - 11s - loss: 0.4576 - tp: 23677.0000 - fp: 7981.0000 - tn: 52594.0000 - fn: 11748.0000 - binary_accuracy: 0.7945 - precision: 0.7479 - recall: 0.6684 - auc: 0.8365 - val_loss: 0.4249 - val_tp: 21460.0000 - val_fp: 6022.0000 - val_tn: 29368.0000 - val_fn: 7150.0000 - val_binary_accuracy: 0.7942 - val_precision: 0.7809 - val_recall: 0.7501 - val_auc: 0.8866\n",
      "Epoch 4/20\n",
      "1500/1500 - 10s - loss: 0.4572 - tp: 23698.0000 - fp: 7992.0000 - tn: 52600.0000 - fn: 11710.0000 - binary_accuracy: 0.7948 - precision: 0.7478 - recall: 0.6693 - auc: 0.8368 - val_loss: 0.4239 - val_tp: 21454.0000 - val_fp: 6025.0000 - val_tn: 29364.0000 - val_fn: 7157.0000 - val_binary_accuracy: 0.7940 - val_precision: 0.7807 - val_recall: 0.7499 - val_auc: 0.8861\n",
      "Epoch 5/20\n",
      "1500/1500 - 10s - loss: 0.4573 - tp: 23699.0000 - fp: 7985.0000 - tn: 52587.0000 - fn: 11729.0000 - binary_accuracy: 0.7946 - precision: 0.7480 - recall: 0.6689 - auc: 0.8371 - val_loss: 0.4236 - val_tp: 21458.0000 - val_fp: 6021.0000 - val_tn: 29366.0000 - val_fn: 7155.0000 - val_binary_accuracy: 0.7941 - val_precision: 0.7809 - val_recall: 0.7499 - val_auc: 0.8861\n",
      "Epoch 6/20\n",
      "1500/1500 - 10s - loss: 0.4570 - tp: 23696.0000 - fp: 7994.0000 - tn: 52600.0000 - fn: 11710.0000 - binary_accuracy: 0.7947 - precision: 0.7477 - recall: 0.6693 - auc: 0.8374 - val_loss: 0.4240 - val_tp: 21460.0000 - val_fp: 6020.0000 - val_tn: 29366.0000 - val_fn: 7154.0000 - val_binary_accuracy: 0.7942 - val_precision: 0.7809 - val_recall: 0.7500 - val_auc: 0.8861\n",
      "Epoch 7/20\n",
      "1500/1500 - 8s - loss: 0.4572 - tp: 23701.0000 - fp: 7991.0000 - tn: 52585.0000 - fn: 11723.0000 - binary_accuracy: 0.7946 - precision: 0.7479 - recall: 0.6691 - auc: 0.8373 - val_loss: 0.4237 - val_tp: 21460.0000 - val_fp: 6021.0000 - val_tn: 29363.0000 - val_fn: 7156.0000 - val_binary_accuracy: 0.7941 - val_precision: 0.7809 - val_recall: 0.7499 - val_auc: 0.8864\n",
      "Epoch 8/20\n",
      "1500/1500 - 8s - loss: 0.4571 - tp: 23696.0000 - fp: 7991.0000 - tn: 52597.0000 - fn: 11716.0000 - binary_accuracy: 0.7947 - precision: 0.7478 - recall: 0.6692 - auc: 0.8374 - val_loss: 0.4241 - val_tp: 21460.0000 - val_fp: 6021.0000 - val_tn: 29362.0000 - val_fn: 7157.0000 - val_binary_accuracy: 0.7941 - val_precision: 0.7809 - val_recall: 0.7499 - val_auc: 0.8862\n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2021-03-29 23:21:27.819454: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/michal/venv/ML-3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:absl:Training complete. Model written to /home/michal/artifact-store/tfx-titanic-training/20210329_231949/Trainer/model/8/serving_model_dir. ModelRun written to /home/michal/artifact-store/tfx-titanic-training/20210329_231949/Trainer/model_run/8\n",
      "INFO:absl:Running publisher for Trainer\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Trainer is finished.\n",
      "INFO:absl:Component Evaluator is running.\n",
      "INFO:absl:Running driver for Evaluator\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "2021-03-29 23:21:29.171178: W ml_metadata/metadata_store/rdbms_metadata_access_object.cc:588] No property is defined for the Type\n",
      "2021-03-29 23:21:29.173477: W ml_metadata/metadata_store/rdbms_metadata_access_object.cc:588] No property is defined for the Type\n",
      "INFO:absl:Running executor for Evaluator\n",
      "WARNING:absl:\"maybe_add_baseline\" and \"maybe_remove_baseline\" are deprecated,\n",
      "        please use \"has_baseline\" instead.\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Survived\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"BinaryAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.5\n",
      "        }\n",
      "        upper_bound {\n",
      "          value: 0.99\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using /home/michal/artifact-store/tfx-titanic-training/20210329_231949/Trainer/model/8/serving_model_dir as  model.\n",
      "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
      "INFO:absl:Evaluating model.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7ff0c079d820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7ff0c079d820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "INFO:absl:Evaluation complete. Results written to /home/michal/artifact-store/tfx-titanic-training/20210329_231949/Evaluator/evaluation/9.\n",
      "INFO:absl:Checking validation results.\n",
      "INFO:absl:Blessing result True written to /home/michal/artifact-store/tfx-titanic-training/20210329_231949/Evaluator/blessing/9.\n",
      "INFO:absl:Running publisher for Evaluator\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Evaluator is finished.\n",
      "INFO:absl:Component InfraValidator is running.\n",
      "INFO:absl:Running driver for InfraValidator\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "2021-03-29 23:21:33.955165: W ml_metadata/metadata_store/rdbms_metadata_access_object.cc:588] No property is defined for the Type\n",
      "INFO:absl:Running executor for InfraValidator\n",
      "INFO:absl:InfraValidator will be run in LOAD_AND_QUERY mode.\n",
      "INFO:absl:tag_set is not given. Using {'serve'} instead.\n",
      "INFO:absl:signature_names are not given. Using ['serving_default'] instead.\n",
      "INFO:absl:Creating temp directory at /home/michal/artifact-store/tfx-titanic-training/20210329_231949/.temp/10/\n",
      "INFO:absl:Starting infra validation (attempt 1/3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Starting LocalDockerRunner(image: tensorflow/serving:latest).\n",
      "INFO:absl:Running container with parameter {'auto_remove': True, 'detach': True, 'publish_all_ports': True, 'image': 'tensorflow/serving:latest', 'environment': {'MODEL_NAME': 'infra-validation-model', 'MODEL_BASE_PATH': '/model'}, 'mounts': [{'Target': '/model/infra-validation-model/1', 'Source': '/home/michal/artifact-store/tfx-titanic-training/20210329_231949/.temp/10/infra-validation-model/1617052893', 'Type': 'bind', 'ReadOnly': True}]}\n",
      "INFO:absl:Error while obtaining model status:\n",
      "<_InactiveRpcError of RPC that terminated with:\n",
      "\tstatus = StatusCode.UNAVAILABLE\n",
      "\tdetails = \"failed to connect to all addresses\"\n",
      "\tdebug_error_string = \"{\"created\":\"@1617052895.466437355\",\"description\":\"Failed to pick subchannel\",\"file\":\"src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":5396,\"referenced_errors\":[{\"created\":\"@1617052895.466434067\",\"description\":\"failed to connect to all addresses\",\"file\":\"src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":397,\"grpc_status\":14}]}\"\n",
      ">\n",
      "INFO:absl:Waiting for model to be loaded...\n",
      "INFO:absl:Model is successfully loaded.\n",
      "INFO:absl:Stopping LocalDockerRunner(image: tensorflow/serving:latest).\n",
      "INFO:absl:Stopping container.\n",
      "INFO:absl:Model passed infra validation.\n",
      "INFO:absl:Running publisher for InfraValidator\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component InfraValidator is finished.\n",
      "INFO:absl:Component Pusher is running.\n",
      "INFO:absl:Running driver for Pusher\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "2021-03-29 23:21:47.286378: W ml_metadata/metadata_store/rdbms_metadata_access_object.cc:588] No property is defined for the Type\n",
      "INFO:absl:Running executor for Pusher\n",
      "INFO:absl:Model version: 1617052907\n",
      "INFO:absl:Model written to serving path /home/michal/serving_model/1617052907.\n",
      "INFO:absl:Model pushed to /home/michal/artifact-store/tfx-titanic-training/20210329_231949/Pusher/pushed_model/11.\n",
      "INFO:absl:Running publisher for Pusher\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Pusher is finished.\n"
     ]
    }
   ],
   "source": [
    "!python local_runner.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run docker container for serving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --rm -p 8500:8500 -p 8501:8501 -p 8503:8503 -v=1 \\\n",
    " --mount type=bind,source=/home/michal/artifact-store/tfx-titanic-training/20210329_231949/Pusher/pushed_model/,target=/models/tfx_titanic_classifier \\\n",
    " -e MODEL_NAME=tfx_titanic_classifier -t tensorflow/serving:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for serializing data to tf.train.Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import features\n",
    "import importlib\n",
    "importlib.reload(features)\n",
    "#import tft \n",
    "import tensorflow_transform as tft\n",
    "\n",
    "feature_tf_example_mapping = {\n",
    "        'Embarked': _bytes_feature,\n",
    "        'Ticket': _bytes_feature,\n",
    "        'Sex': _bytes_feature,\n",
    "        'Name': _bytes_feature,\n",
    "        'Cabin': _bytes_feature,\n",
    "        'Age': _float_feature,\n",
    "        'Fare': _float_feature,\n",
    "        'Parch': _int64_feature,\n",
    "        'PassengerId': _int64_feature,\n",
    "        'Pclass': _int64_feature,\n",
    "        'SibSp': _int64_feature\n",
    "    }\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  if isinstance(value, str):\n",
    "    value = str.encode(value) # str wont work, we need bytes\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_example(data):\n",
    "  \"\"\"\n",
    "  Creates a tf.train.Example message ready to be written to a file.\n",
    "  data : dict\n",
    "            dictionary with data in key: value format\n",
    "  \"\"\"\n",
    "  if isinstance(data, pd.core.frame.DataFrame):\n",
    "        data = data.to_dict(orient='records')\n",
    "  \n",
    "  # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n",
    "  # data type.\n",
    "  feature = { key: feature_tf_example_mapping[key](data[key]) for key in data.keys()}\n",
    "                                              \n",
    "  # Create a Features message using tf.train.Example.\n",
    "\n",
    "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "  return example_proto.SerializeToString()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "\n",
    "from tensorflow.core.framework import types_pb2\n",
    "from tensorflow.core.framework import tensor_pb2\n",
    "from tensorflow.core.framework import tensor_shape_pb2\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc \n",
    "\n",
    "\n",
    "def predict_titanic(request_data):\n",
    "    \n",
    "    serialized_examples_array = [serialize_example(row) for row in request_data] # array od serialized examples\n",
    "    server = 'localhost:8500'\n",
    "    host, port = server.split(':')\n",
    "\n",
    "    channel = grpc.insecure_channel(server)\n",
    "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "    \n",
    "    dims = [tensor_shape_pb2.TensorShapeProto.Dim(size=len(request_data))]\n",
    "    tensor_shape_proto = tensor_shape_pb2.TensorShapeProto(dim=dims)\n",
    "    tensor_proto = tensor_pb2.TensorProto(\n",
    "                dtype=types_pb2.DT_STRING,\n",
    "                tensor_shape=tensor_shape_proto,\n",
    "                string_val=serialized_examples_array)\n",
    "\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = \"tfx_titanic_classifier\"\n",
    "    request.model_spec.signature_name = 'serving_default'\n",
    "    request.inputs['examples'].CopyFrom(tensor_proto)\n",
    "    result_future = stub.Predict(request, 30.)\n",
    "    \n",
    "    return result_future\n",
    "\n",
    "def parse_prediction_result(prediction_result):\n",
    "    outputs_tensor_proto = prediction_result.outputs[\"output_0\"]\n",
    "    shape = tf.TensorShape(outputs_tensor_proto.tensor_shape)\n",
    "    outputs = np.array(outputs_tensor_proto.float_val).reshape(shape)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'\\n\\xfb\\x01\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01C\\n\\x10\\n\\x05Cabin\\x12\\x07\\n\\x05\\n\\x03C85\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x18B\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x16\\n\\x06Ticket\\x12\\x0c\\n\\n\\n\\x08PC 17599\\n\\x11\\n\\x03Sex\\x12\\n\\n\\x08\\n\\x06female\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\r\\x91\\x8eB\\n?\\n\\x04Name\\x127\\n5\\n3Cumings, Mrs. John Bradley (Florence Briggs Thayer)', b'\\n\\xe3\\x01\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\xd0A\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\xfd@\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\"\\n\\x04Name\\x12\\x1a\\n\\x18\\n\\x16Heikkinen, Miss. Laina\\n\\x11\\n\\x03Sex\\x12\\n\\n\\x08\\n\\x06female\\n\\x1e\\n\\x06Ticket\\x12\\x14\\n\\x12\\n\\x10STON/O2. 3101282\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00', b'\\n\\xf3\\x01\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x0cB\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04ffTB\\n\\x14\\n\\x06Ticket\\x12\\n\\n\\x08\\n\\x06113803\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x11\\n\\x05Cabin\\x12\\x08\\n\\x06\\n\\x04C123\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n8\\n\\x04Name\\x120\\n.\\n,Futrelle, Mrs. Jacques Heath (Lily May Peel)\\n\\x11\\n\\x03Sex\\x12\\n\\n\\x08\\n\\x06female\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x01', b'\\n\\xf4\\x01\\n=\\n\\x04Name\\x125\\n3\\n1Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\t\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\xd8A\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\xff!2A\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x03Sex\\x12\\n\\n\\x08\\n\\x06female\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x14\\n\\x06Ticket\\x12\\n\\n\\x08\\n\\x06347742', b\"\\n\\xe6\\x01\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01C\\n\\x14\\n\\x06Ticket\\x12\\n\\n\\x08\\n\\x06237736\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`A\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x91\\xf0A\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\n\\n/\\n\\x04Name\\x12'\\n%\\n#Nasser, Mrs. Nicholas (Adele Achem)\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x03Sex\\x12\\n\\n\\x08\\n\\x06female\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x02\", b'\\n\\xe5\\x01\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x03Sex\\x12\\n\\n\\x08\\n\\x06female\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x0b\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\x85A\\n\\x0f\\n\\x05Cabin\\x12\\x06\\n\\x04\\n\\x02G6\\n+\\n\\x04Name\\x12#\\n!\\n\\x1fSandstrom, Miss. Marguerite Rut\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\x15\\n\\x06Ticket\\x12\\x0b\\n\\t\\n\\x07PP 9549\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x80@\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x03', b'\\n\\xdf\\x01\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x05Cabin\\x12\\x08\\n\\x06\\n\\x04C103\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04ff\\xd4A\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x0c\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n$\\n\\x04Name\\x12\\x1c\\n\\x1a\\n\\x18Bonnell, Miss. Elizabeth\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x03Sex\\x12\\n\\n\\x08\\n\\x06female\\n\\x14\\n\\x06Ticket\\x12\\n\\n\\x08\\n\\x06113783\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00hB', b'\\n\\xe3\\x01\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x10\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x11\\n\\x03Sex\\x12\\n\\n\\x08\\n\\x06female\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\\\B\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x14\\n\\x06Ticket\\x12\\n\\n\\x08\\n\\x06248706\\n,\\n\\x04Name\\x12$\\n\"\\n Hewlett, Mrs. (Mary D Kingcome) \\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x80A\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x02', b'\\n\\xdd\\x01\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\xc0\\x7f\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n(\\n\\x04Name\\x12 \\n\\x1e\\n\\x1cWilliams, Mr. Charles Eugene\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x12\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00PA\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\x14\\n\\x06Ticket\\x12\\n\\n\\x08\\n\\x06244373\\n\\x0f\\n\\x03Sex\\x12\\x08\\n\\x06\\n\\x04male', b'\\n\\xd8\\x01\\n\\x12\\n\\x06Ticket\\x12\\x08\\n\\x06\\n\\x042649\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x03Sex\\x12\\n\\n\\x08\\n\\x06female\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x0433\\xe7@\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\xc0\\x7f\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01C\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x14\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n#\\n\\x04Name\\x12\\x1b\\n\\x19\\n\\x17Masselmani, Mrs. Fatima']\n",
      "[b'\\n\\xdb\\x01\\n#\\n\\x04Name\\x12\\x1b\\n\\x19\\n\\x17Braund, Mr. Owen Harris\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\xe8@\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x17\\n\\x06Ticket\\x12\\r\\n\\x0b\\n\\tA/5 21171\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x0f\\n\\x03Sex\\x12\\x08\\n\\x06\\n\\x04male\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\xb0A', b'\\n\\xd9\\x01\\n\\x14\\n\\x06Ticket\\x12\\n\\n\\x08\\n\\x06373450\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\x0f\\n\\x03Sex\\x12\\x08\\n\\x06\\n\\x04male\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\x00A\\n$\\n\\x04Name\\x12\\x1c\\n\\x1a\\n\\x18Allen, Mr. William Henry\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x05\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x0cB\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x00', b'\\n\\xd1\\x01\\n\\x0f\\n\\x03Sex\\x12\\x08\\n\\x06\\n\\x04male\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x14\\n\\x06Ticket\\x12\\n\\n\\x08\\n\\x06330877\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01Q\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x042U\\x07A\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x06\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\xc0\\x7f\\n\\x1c\\n\\x04Name\\x12\\x14\\n\\x12\\n\\x10Moran, Mr. James', b'\\n\\xda\\x01\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x0f\\n\\x03Sex\\x12\\x08\\n\\x06\\n\\x04male\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00XB\\n#\\n\\x04Name\\x12\\x1b\\n\\x19\\n\\x17McCarthy, Mr. Timothy J\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x043sOB\\n\\x13\\n\\x06Ticket\\x12\\t\\n\\x07\\n\\x0517463\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x07\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x10\\n\\x05Cabin\\x12\\x07\\n\\x05\\n\\x03E46', b'\\n\\xdf\\x01\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n*\\n\\x04Name\\x12\"\\n \\n\\x1ePalsson, Master. Gosta Leonard\\n\\x0f\\n\\x03Sex\\x12\\x08\\n\\x06\\n\\x04male\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x08\\n\\x14\\n\\x06Ticket\\x12\\n\\n\\x08\\n\\x06349909\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00@\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\x9a\\x99\\xa8A', b'\\n\\xe2\\x01\\n\\x0f\\n\\x03Sex\\x12\\x08\\n\\x06\\n\\x04male\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\xcd\\xcc\\x00A\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\xa0A\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\r\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x17\\n\\x06Ticket\\x12\\r\\n\\x0b\\n\\tA/5. 2151\\n*\\n\\x04Name\\x12\"\\n \\n\\x1eSaundercock, Mr. William Henry\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x03', b\"\\n\\xdc\\x01\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x05\\n'\\n\\x04Name\\x12\\x1f\\n\\x1d\\n\\x1bAndersson, Mr. Anders Johan\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x0433\\xfaA\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x1cB\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x14\\n\\x06Ticket\\x12\\n\\n\\x08\\n\\x06347082\\n\\x0f\\n\\x03Sex\\x12\\x08\\n\\x06\\n\\x04male\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x0e\", b'\\n\\xe7\\x01\\n0\\n\\x04Name\\x12(\\n&\\n$Vestrom, Miss. Hulda Amanda Adolfina\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x0f\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\x9bU\\xfb@\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00`A\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x14\\n\\x06Ticket\\x12\\n\\n\\x08\\n\\x06350406\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x03Sex\\x12\\n\\n\\x08\\n\\x06female', b'\\n\\xd5\\x01\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x11\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00@\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\xe9A\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01Q\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x0f\\n\\x03Sex\\x12\\x08\\n\\x06\\n\\x04male\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n \\n\\x04Name\\x12\\x18\\n\\x16\\n\\x14Rice, Master. Eugene\\n\\x14\\n\\x06Ticket\\x12\\n\\n\\x08\\n\\x06382652', b'\\n\\xfa\\x01\\n\\x14\\n\\x0bPassengerId\\x12\\x05\\x1a\\x03\\n\\x01\\x13\\nC\\n\\x04Name\\x12;\\n9\\n7Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)\\n\\x10\\n\\x04Fare\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x90A\\n\\x0e\\n\\x05SibSp\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x03Sex\\x12\\n\\n\\x08\\n\\x06female\\n\\r\\n\\x05Cabin\\x12\\x04\\n\\x02\\n\\x00\\n\\x11\\n\\x08Embarked\\x12\\x05\\n\\x03\\n\\x01S\\n\\x0f\\n\\x06Pclass\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x0f\\n\\x03Age\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\xf8A\\n\\x0e\\n\\x05Parch\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x14\\n\\x06Ticket\\x12\\n\\n\\x08\\n\\x06345763']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-251-dc925a5a238e>:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_survived_examples_df['Survived_prediction'] = parsed_prediction_results_survived\n",
      "<ipython-input-251-dc925a5a238e>:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_dead_examples_df['Survived_prediction'] = parsed_prediction_results_dead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0.924290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>0.578618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0.888190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>0.567588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>0.859664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>0.692569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "      <td>0.849998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>0.703438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "1             2         1       1   \n",
       "2             3         1       3   \n",
       "3             4         1       1   \n",
       "8             9         1       3   \n",
       "9            10         1       2   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "15           16         1       2   \n",
       "17           18         1       2   \n",
       "19           20         1       3   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                              Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "8   Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                 Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "15                   Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
       "17                       Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "19                            Masselmani, Mrs. Fatima  female   NaN      0   \n",
       "\n",
       "    Parch            Ticket     Fare Cabin Embarked  Survived_prediction  \n",
       "1       0          PC 17599  71.2833   C85        C             0.924290  \n",
       "2       0  STON/O2. 3101282   7.9250              S             0.578618  \n",
       "3       0            113803  53.1000  C123        S             0.888190  \n",
       "8       2            347742  11.1333              S             0.567588  \n",
       "9       0            237736  30.0708              C             0.859664  \n",
       "10      1           PP 9549  16.7000    G6        S             0.692569  \n",
       "11      0            113783  26.5500  C103        S             0.849998  \n",
       "15      0            248706  16.0000              S             0.703438  \n",
       "17      0            244373  13.0000              S                  NaN  \n",
       "19      0              2649   7.2250              C                  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>0.099442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>0.083922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td></td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>0.311655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>0.050752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>0.097355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>0.083896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>0.610067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td></td>\n",
       "      <td>Q</td>\n",
       "      <td>0.077981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>0.580481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "0             1         0       3   \n",
       "4             5         0       3   \n",
       "5             6         0       3   \n",
       "6             7         0       1   \n",
       "7             8         0       3   \n",
       "12           13         0       3   \n",
       "13           14         0       3   \n",
       "14           15         0       3   \n",
       "16           17         0       3   \n",
       "18           19         0       3   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "0                             Braund, Mr. Owen Harris    male  22.0      1   \n",
       "4                            Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                    Moran, Mr. James    male   NaN      0   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                      Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "12                     Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                        Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14               Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "16                               Rice, Master. Eugene    male   2.0      4   \n",
       "18  Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "\n",
       "    Parch     Ticket     Fare Cabin Embarked  Survived_prediction  \n",
       "0       0  A/5 21171   7.2500              S             0.099442  \n",
       "4       0     373450   8.0500              S             0.083922  \n",
       "5       0     330877   8.4583              Q                  NaN  \n",
       "6       0      17463  51.8625   E46        S             0.311655  \n",
       "7       1     349909  21.0750              S             0.050752  \n",
       "12      0  A/5. 2151   8.0500              S             0.097355  \n",
       "13      5     347082  31.2750              S             0.083896  \n",
       "14      0     350406   7.8542              S             0.610067  \n",
       "16      1     382652  29.1250              Q             0.077981  \n",
       "18      0     345763  18.0000              S             0.580481  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92429006 0.57861793 0.88819003 0.56758779 0.85966432 0.6925689\n",
      " 0.84999764 0.70343751        nan        nan]\n",
      "[0.09944177 0.08392188        nan 0.31165546 0.05075216 0.09735522\n",
      " 0.08389616 0.61006731 0.07798055 0.58048129]\n"
     ]
    }
   ],
   "source": [
    "titanic_types  = {\n",
    "    'PassengerId': np.int32,\n",
    "    'Pclass': np.int32,\n",
    "    'Name': np.object,\n",
    "    'Sex': np.object,\n",
    "    'Age': np.float32,\n",
    "    'SibSp': np.int32,\n",
    "    'Parch': np.int32,\n",
    "    'Ticket': np.object,\n",
    "    'Fare': np.float32,\n",
    "    'Cabin': np.object,\n",
    "    'Embarked': np.object,\n",
    "    'Survived': np.int32,\n",
    "}\n",
    "converters = {'Cabin': str, 'Name': str, 'Ticket': str, 'Sex': str, 'Embarked': str}\n",
    "\n",
    "titanic_test_df = pd.read_csv(local_test_filepath, converters=converters)\n",
    "titanic_train_df = pd.read_csv(local_train_filepath, converters=converters)\n",
    "                     \n",
    "#titanic_test_df.head(10)\n",
    "\n",
    "titanic_train_df_survived = titanic_train_df[titanic_train_df['Survived'] == 1]\n",
    "titanic_train_df_dead = titanic_train_df[titanic_train_df['Survived'] == 0]\n",
    "\n",
    "train_survived_examples_df =  titanic_train_df_survived.head(10)\n",
    "train_dead_examples_df =  titanic_train_df_dead.head(10)\n",
    "\n",
    "train_survived_examples_data = train_survived_examples_df.to_dict(orient='records')\n",
    "train_dead_examples_data = train_dead_examples_df.to_dict(orient='records')\n",
    "\n",
    "#remove Survived label\n",
    "for example in train_survived_examples_data:\n",
    "    example.pop('Survived', None)\n",
    "for example in train_dead_examples_data:\n",
    "    example.pop('Survived', None)\n",
    "\n",
    "prediction_result_for_survived = predict_titanic(train_survived_examples_data)\n",
    "prediction_result_for_dead = predict_titanic(train_dead_examples_data)\n",
    "\n",
    "parsed_prediction_results_survived = parse_prediction_result(prediction_result_for_survived)\n",
    "parsed_prediction_results_dead = parse_prediction_result(prediction_result_for_dead)\n",
    "\n",
    "train_survived_examples_df['Survived_prediction'] = parsed_prediction_results_survived\n",
    "train_dead_examples_df['Survived_prediction'] = parsed_prediction_results_dead\n",
    "\n",
    "#pprint(train_survived_examples_df)\n",
    "display(train_survived_examples_df)\n",
    "display(train_dead_examples_df)\n",
    "print(parsed_prediction_results_survived)\n",
    "print(parsed_prediction_results_dead)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[size: 10\n",
      "]\n",
      "dtype: DT_FLOAT\n",
      "tensor_shape {\n",
      "  dim {\n",
      "    size: 10\n",
      "  }\n",
      "}\n",
      "float_val: 0.1257660686969757\n",
      "float_val: 0.53336101770401\n",
      "float_val: 0.20011577010154724\n",
      "float_val: 0.09094074368476868\n",
      "float_val: 0.6478143930435181\n",
      "float_val: 0.10341450572013855\n",
      "float_val: 0.6724532246589661\n",
      "float_val: 0.23720216751098633\n",
      "float_val: 0.697922945022583\n",
      "float_val: 0.03467932343482971\n",
      "\n",
      "[0.12576607 0.53336102 0.20011577 0.09094074 0.64781439 0.10341451\n",
      " 0.67245322 0.23720217 0.69792295 0.03467932]\n"
     ]
    }
   ],
   "source": [
    "first10 = titanic.iloc[:10].to_dict(orient='records')\n",
    "prediction_result = predict_titanic(first10)\n",
    "type(prediction_result)\n",
    "#prediction_result.outputs.values\n",
    "outputs_tensor_proto = prediction_result.outputs[\"output_0\"]\n",
    "print(outputs_tensor_proto)\n",
    "\n",
    "prediction_result\n",
    "\n",
    "\n",
    "shape = tf.TensorShape(outputs_tensor_proto.tensor_shape)\n",
    "#outputs = tf.constant(outputs_tensor_proto.float_val, shape=shape)\n",
    "outputs = np.array(outputs_tensor_proto.float_val).reshape(shape)\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
